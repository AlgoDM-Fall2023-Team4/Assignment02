{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f02f3fc",
      "metadata": {
        "id": "5f02f3fc"
      },
      "source": [
        "# Project Overview\n",
        "Perform data analysis and data preparation tasks to train a Linear Regression model to predict future ROI (Return On Investment) of variable ad spend budgets across multiple channels including search, video, social media, and email using Snowpark for Python, Snowpark ML and Streamlit. By the end of the session, you will have an interactive web application deployed visualizing the ROI of different allocated advertising spend budgets.\n",
        "\n",
        "### Data Engineering -- Data Analysis and Data Preparation\n",
        "In this Notebook, we will focus on Data Engineering in Snowflake using Snowpark for Python.\n",
        "\n",
        "* Establish secure connection to Snowflake\n",
        "* Load data from Snowflake tables into Snowpark DataFrames\n",
        "* Perform Exploratory Data Analysis on Snowpark DataFrames\n",
        "* Pivot and Join data from multiple tables using Snowpark DataFrames\n",
        "* Demostrate how to automate data preparation using Snowflake Tasks\n",
        "\n",
        "*For environment setup including loading data into Snowflake tables, and step-by-step instructions, please refer to the [QuickStart Guide](https://quickstarts.snowflake.com/guide/getting_started_with_dataengineering_ml_using_snowpark_python/index.html#0).*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2e1c4a",
      "metadata": {
        "id": "6e2e1c4a"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snowflake-connector-python snowflake-snowpark-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzutnbhQY-i-",
        "outputId": "a00549da-c55b-436e-b16f-168ac7c87b93"
      },
      "id": "tzutnbhQY-i-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snowflake-connector-python in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: snowflake-snowpark-python in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.5.1)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.16.0)\n",
            "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (41.0.4)\n",
            "Requirement already satisfied: oscrypto<2.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.3.0)\n",
            "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (23.2.0)\n",
            "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.19.0)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2023.7.22)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (4.5.0)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.12.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (2.4.0)\n",
            "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (3.11.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python) (0.12.1)\n",
            "Requirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python) (0.41.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python) (6.0.1)\n",
            "Requirement already satisfied: cloudpickle<=2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "persistent-reasoning",
      "metadata": {
        "papermill": {
          "duration": 0.872363,
          "end_time": "2021-05-15T09:33:41.413139",
          "exception": false,
          "start_time": "2021-05-15T09:33:40.540776",
          "status": "completed"
        },
        "tags": [],
        "id": "persistent-reasoning"
      },
      "outputs": [],
      "source": [
        "# Snowpark for Python\n",
        "from snowflake.snowpark.session import Session\n",
        "from snowflake.snowpark.functions import month,year,col,sum\n",
        "from snowflake.snowpark.version import VERSION\n",
        "\n",
        "# Misc\n",
        "import json\n",
        "import logging\n",
        "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
        "logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b855e80e",
      "metadata": {
        "id": "b855e80e"
      },
      "source": [
        "### Establish Secure Connection to Snowflake\n",
        "\n",
        "Using the Snowpark Python API, itâ€™s quick and easy to establish a secure connection between Snowflake and Notebook.\n",
        "\n",
        " *Note: Other connection options include Username/Password, MFA, OAuth, Okta, SSO*\n",
        "\n",
        "TIP: Learn more about [Session](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/session) object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rotary-dairy",
      "metadata": {
        "papermill": {
          "duration": 0.092202,
          "end_time": "2021-05-15T09:34:12.813622",
          "exception": false,
          "start_time": "2021-05-15T09:34:12.721420",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rotary-dairy",
        "outputId": "f8d997b6-e3c1-4373-f8de-6b7e8fd83b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User                        : POOSAPRANITHA\n",
            "Role                        : \"ACCOUNTADMIN\"\n",
            "Database                    : \"A2_DB\"\n",
            "Schema                      : \"A2_SCHEMA\"\n",
            "Warehouse                   : \"COMPUTE_WH\"\n",
            "Snowflake version           : 7.37.2\n",
            "Snowpark for Python version : 1.9.0\n"
          ]
        }
      ],
      "source": [
        "# Create Snowflake Session object\n",
        "connection_parameters = {\n",
        "    \"account\": \"zuptiwu-sx86855\",\n",
        "    \"user\": \"POOSAPRANITHA\",\n",
        "    \"password\": \"Infinity99\",\n",
        "    \"database\": \"A2_DB\",\n",
        "    \"schema\": \"A2_SCHEMA\"\n",
        "}\n",
        "session = Session.builder.configs(connection_parameters).create()\n",
        "session.sql_simplifier_enabled = True\n",
        "\n",
        "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
        "snowpark_version = VERSION\n",
        "\n",
        "# Current Environment Details\n",
        "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
        "print('Role                        : {}'.format(session.get_current_role()))\n",
        "print('Database                    : {}'.format(session.get_current_database()))\n",
        "print('Schema                      : {}'.format(session.get_current_schema()))\n",
        "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
        "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
        "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ff9bbb",
      "metadata": {
        "id": "78ff9bbb"
      },
      "source": [
        "### Load Aggregated Campaign Spend Data from Snowflake table into Snowpark DataFrame\n",
        "\n",
        "Let's first load the campaign spend data. This table contains ad click data that has been aggregated to show daily spend across digital ad channels including search engines, social media, email and video.\n",
        "\n",
        "*Note: Some other ways to load data in a Snowpark DataFrame*\n",
        "* *session.sql(\"select col1, col2... from tableName\")*\n",
        "* *session.read.options({\"field_delimiter\": \",\", \"skip_header\": 1}).schema(user_schema).csv(\"@mystage/testCSV.csv\")*\n",
        "* *session.read.parquet(\"@stageName/path/to/file\")*\n",
        "* *session.create_dataframe([1,2,3], schema=[\"col1\"])*\n",
        "\n",
        "TIP: Learn more about [Snowpark DataFrames](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/dataframe).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80bed43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80bed43",
        "outputId": "29e7b542-a120-49ef-fb19-9c9828abf4cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'queries': ['SELECT  *  FROM (campaign_spend)'], 'post_actions': []}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "snow_df_spend = session.table('campaign_spend')\n",
        "snow_df_spend.queries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b671d01b",
      "metadata": {
        "id": "b671d01b"
      },
      "source": [
        "Actions like *show(), collect(), count()* send the DataFrame SQL for execution on the server\n",
        "\n",
        "*Note: History object provides the query ID which can be helpful for debugging as well as the SQL query executed on the server.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7129be1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7129be1",
        "outputId": "77b6ae88-3fad-4c46-f7ca-64ef4d6e6e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------------------\n",
            "|\"CAMPAIGN\"              |\"CHANNEL\"      |\"DATE\"      |\"TOTAL_CLICKS\"  |\"TOTAL_COST\"  |\"ADS_SERVED\"  |\n",
            "------------------------------------------------------------------------------------------------------\n",
            "|winter_sports           |video          |2012-06-03  |213             |1762          |426           |\n",
            "|sports_across_cultures  |video          |2012-06-02  |87              |678           |157           |\n",
            "|building_community      |search_engine  |2012-06-03  |66              |471           |134           |\n",
            "|world_series            |social_media   |2017-12-28  |72              |591           |149           |\n",
            "|winter_sports           |email          |2018-02-09  |252             |1841          |473           |\n",
            "|spring_break            |video          |2017-11-14  |162             |1155          |304           |\n",
            "|nba_finals              |email          |2017-11-22  |68              |480           |134           |\n",
            "|winter_sports           |social_media   |2018-03-10  |227             |1797          |454           |\n",
            "|spring_break            |search_engine  |2017-08-30  |150             |1226          |302           |\n",
            "|uefa                    |video          |2017-09-30  |81              |701           |168           |\n",
            "|uefa                    |video          |2018-01-23  |73              |545           |141           |\n",
            "|sports_across_cultures  |search_engine  |2017-10-12  |73              |544           |143           |\n",
            "|winter_sports           |social_media   |2018-01-14  |207             |1640          |418           |\n",
            "|youth_on_course         |search_engine  |2018-03-29  |164             |1036          |291           |\n",
            "|memorial_day            |social_media   |2018-01-18  |131             |1119          |281           |\n",
            "|family_history          |video          |2018-03-24  |88              |646           |166           |\n",
            "|memorial_day            |search_engine  |2017-12-09  |134             |968           |262           |\n",
            "|youth_in_action         |search_engine  |2018-03-24  |194             |1642          |411           |\n",
            "|winter_sports           |video          |2017-10-25  |208             |1673          |431           |\n",
            "|thanksgiving_football   |video          |2017-11-10  |82              |633           |165           |\n",
            "------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[QueryRecord(query_id='01afc9e1-0001-6db5-0000-0004bbb2704d', sql_text='SELECT  *  FROM campaign_spend LIMIT 20')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "with session.query_history() as history:\n",
        "    snow_df_spend.show(20)\n",
        "history.queries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e671ff3",
      "metadata": {
        "id": "6e671ff3"
      },
      "source": [
        "### Total Spend per Year and Month For All Channels\n",
        "\n",
        "Let's transform the data so we can see total cost per year/month per channel using _group_by()_ and _agg()_ Snowpark DataFrame functions.\n",
        "\n",
        "TIP: For a full list of functions, refer to the [documentation](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "laden-contest",
      "metadata": {
        "papermill": {
          "duration": 0.07724,
          "end_time": "2021-05-15T09:33:41.657494",
          "exception": false,
          "start_time": "2021-05-15T09:33:41.580254",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laden-contest",
        "outputId": "ab8a82f5-45c6-4fb8-c125-b0801607f101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------\n",
            "|\"YEAR\"  |\"MONTH\"  |\"CHANNEL\"      |\"TOTAL_COST\"  |\n",
            "---------------------------------------------------\n",
            "|2012    |5        |search_engine  |516431        |\n",
            "|2012    |5        |video          |516729        |\n",
            "|2012    |5        |email          |517208        |\n",
            "|2012    |5        |social_media   |517618        |\n",
            "|2012    |6        |video          |501098        |\n",
            "|2012    |6        |search_engine  |506497        |\n",
            "|2012    |6        |social_media   |504679        |\n",
            "|2012    |6        |email          |501947        |\n",
            "|2012    |7        |search_engine  |522780        |\n",
            "|2012    |7        |email          |518405        |\n",
            "---------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Stats per Month per Channel\n",
        "snow_df_spend_per_channel = snow_df_spend.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n",
        "    with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n",
        "\n",
        "snow_df_spend_per_channel.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f67d9af",
      "metadata": {
        "id": "7f67d9af"
      },
      "source": [
        "### Pivot on Channel: Total Spend Across All Channels\n",
        "\n",
        " Let's further transform the campaign spend data so that **each row will represent total cost across all channels** per year/month using _pivot()_ and _sum()_ Snowpark DataFrame functions. This transformation will enable us to join with the revenue table such that we will have our input features and target variable in a single table for model training.\n",
        "\n",
        " TIP: For a full list of functions, refer to the [documentation](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f8a63e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8a63e7",
        "outputId": "5aab76b0-a88a-42d8-ddb7-dedbbf043e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------\n",
            "|\"YEAR\"  |\"MONTH\"  |\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\n",
            "---------------------------------------------------------------------------\n",
            "|2012    |5        |516431           |517618          |516729   |517208   |\n",
            "|2012    |6        |506497           |504679          |501098   |501947   |\n",
            "|2012    |7        |522780           |521395          |522762   |518405   |\n",
            "|2012    |8        |519959           |520537          |520685   |521584   |\n",
            "|2012    |9        |507211           |507404          |511364   |507363   |\n",
            "|2012    |10       |518942           |520863          |522768   |519950   |\n",
            "|2012    |11       |505715           |505221          |505292   |503748   |\n",
            "|2012    |12       |520148           |520711          |521427   |520724   |\n",
            "|2013    |1        |522151           |518635          |520583   |521167   |\n",
            "|2013    |2        |467736           |474679          |469856   |469784   |\n",
            "---------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "snow_df_spend_per_month = snow_df_spend_per_channel.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n",
        "snow_df_spend_per_month = snow_df_spend_per_month.select(\n",
        "    col(\"YEAR\"),\n",
        "    col(\"MONTH\"),\n",
        "    col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n",
        "    col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n",
        "    col(\"'video'\").as_(\"VIDEO\"),\n",
        "    col(\"'email'\").as_(\"EMAIL\")\n",
        ")\n",
        "snow_df_spend_per_month.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a81f69",
      "metadata": {
        "id": "79a81f69"
      },
      "source": [
        "### Save Transformed Data into Snowflake Table\n",
        "\n",
        "Let's save the transformed data into a Snowflake table *SPEND_PER_MONTH*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ad6e10",
      "metadata": {
        "id": "b1ad6e10"
      },
      "outputs": [],
      "source": [
        "snow_df_spend_per_month.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c081551b",
      "metadata": {
        "id": "c081551b"
      },
      "source": [
        "### Automation: Run Campaign Spend Data Transformations As a Snowflake Task\n",
        "\n",
        "*Note: Optionally you can run all these transformations as an automated task by deploying the code to Snowflake as a Snowpark Stored Procedure and executing it as a Snowflake Task.*\n",
        "\n",
        "TIP: Learn more about [Stored Procedures](https://docs.snowflake.com/en/sql-reference/stored-procedures-python) and [Snowflake Tasks](https://docs.snowflake.com/en/sql-reference/sql/create-task)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a20b994",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a20b994",
        "outputId": "fa636b5f-8689-4d80-e57d-e1fd74c0d97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Failed to get the local distribution of package snowflake-snowpark-python: (cloudpickle 2.2.1 (/usr/local/lib/python3.10/dist-packages), Requirement.parse('cloudpickle<=2.0.0,>=1.6.0; python_version < \"3.11\"'), {'snowflake-snowpark-python'})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(status='Task CAMPAIGN_SPEND_DATA_PIPELINE_TASK successfully created.')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def campaign_spend_data_pipeline(session: Session) -> str:\n",
        "  # DATA TRANSFORMATIONS\n",
        "  # Perform the following actions to transform the data\n",
        "\n",
        "  # Load the campaign spend data\n",
        "  snow_df_spend_t = session.table('campaign_spend')\n",
        "\n",
        "  # Transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions\n",
        "  snow_df_spend_per_channel_t = snow_df_spend_t.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n",
        "      with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n",
        "\n",
        "  # Transform the data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions\n",
        "  snow_df_spend_per_month_t = snow_df_spend_per_channel_t.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n",
        "  snow_df_spend_per_month_t = snow_df_spend_per_month_t.select(\n",
        "      col(\"YEAR\"),\n",
        "      col(\"MONTH\"),\n",
        "      col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n",
        "      col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n",
        "      col(\"'video'\").as_(\"VIDEO\"),\n",
        "      col(\"'email'\").as_(\"EMAIL\")\n",
        "  )\n",
        "\n",
        "  # Save transformed data\n",
        "  snow_df_spend_per_month_t.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')\n",
        "\n",
        "# Register data pipelining function as a Stored Procedure so it can be run as a task\n",
        "session.sproc.register(\n",
        "  func=campaign_spend_data_pipeline,\n",
        "  name=\"campaign_spend_data_pipeline\",\n",
        "  packages=['snowflake-snowpark-python'],\n",
        "  is_permanent=True,\n",
        "  stage_location=\"@A2_sprocs\",\n",
        "  replace=True)\n",
        "\n",
        "campaign_spend_data_pipeline_task = \"\"\"\n",
        "CREATE OR REPLACE TASK campaign_spend_data_pipeline_task\n",
        "    WAREHOUSE = 'A2_WH'\n",
        "    SCHEDULE  = '3 MINUTE'\n",
        "AS\n",
        "    CALL campaign_spend_data_pipeline()\n",
        "\"\"\"\n",
        "session.sql(campaign_spend_data_pipeline_task).collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47937d8b",
      "metadata": {
        "id": "47937d8b"
      },
      "source": [
        "### Total Revenue per Year And Month"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cd4f53",
      "metadata": {
        "id": "55cd4f53"
      },
      "source": [
        "Now let's load revenue table and transform the data into revenue per year/month using *group_by() and agg()* functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013b2276",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "013b2276",
        "outputId": "e857f4ce-c1bb-4f52-d4e1-5f4d97e003cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "|\"YEAR\"  |\"MONTH\"  |\"REVENUE\"   |\n",
            "---------------------------------\n",
            "|2012    |5        |3264300.11  |\n",
            "|2012    |6        |3208482.33  |\n",
            "|2012    |7        |3311966.98  |\n",
            "|2012    |8        |3311752.81  |\n",
            "|2012    |9        |3208563.06  |\n",
            "|2012    |10       |3334028.46  |\n",
            "|2012    |11       |3185894.64  |\n",
            "|2012    |12       |3334570.96  |\n",
            "|2013    |1        |3316455.44  |\n",
            "|2013    |2        |2995042.21  |\n",
            "---------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "snow_df_revenue = session.table('monthly_revenue')\n",
        "snow_df_revenue_per_month = snow_df_revenue.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n",
        "snow_df_revenue_per_month.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccadfae4",
      "metadata": {
        "id": "ccadfae4"
      },
      "source": [
        "### Join Total Spend and Total Revenue per Year and Month Across All Channels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1035d996",
      "metadata": {
        "id": "1035d996"
      },
      "source": [
        "Next let's **join this revenue data with the transformed campaign spend data** so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d49b236",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d49b236",
        "outputId": "0888de6e-94bf-46eb-e7fd-afbf690852ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------\n",
            "|\"YEAR\"  |\"MONTH\"  |\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\"REVENUE\"   |\n",
            "----------------------------------------------------------------------------------------\n",
            "|2012    |5        |516431           |517618          |516729   |517208   |3264300.11  |\n",
            "|2012    |6        |506497           |504679          |501098   |501947   |3208482.33  |\n",
            "|2012    |7        |522780           |521395          |522762   |518405   |3311966.98  |\n",
            "|2012    |8        |519959           |520537          |520685   |521584   |3311752.81  |\n",
            "|2012    |9        |507211           |507404          |511364   |507363   |3208563.06  |\n",
            "|2012    |10       |518942           |520863          |522768   |519950   |3334028.46  |\n",
            "|2012    |11       |505715           |505221          |505292   |503748   |3185894.64  |\n",
            "|2012    |12       |520148           |520711          |521427   |520724   |3334570.96  |\n",
            "|2013    |1        |522151           |518635          |520583   |521167   |3316455.44  |\n",
            "|2013    |2        |467736           |474679          |469856   |469784   |2995042.21  |\n",
            "----------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "snow_df_spend_and_revenue_per_month = snow_df_spend_per_month.join(snow_df_revenue_per_month, [\"YEAR\",\"MONTH\"])\n",
        "snow_df_spend_and_revenue_per_month.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4aaaba",
      "metadata": {
        "id": "fe4aaaba"
      },
      "source": [
        "### >>>>>>>>>> *Examine Snowpark DataFrame Query and Execution Plan* <<<<<<<<<<\n",
        "\n",
        "Snowpark makes is really convenient to look at the DataFrame query and execution plan using _explain()_ Snowpark DataFrame function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c78499",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9c78499",
        "outputId": "c126b5ed-e7f8-458a-8d0a-26ddcad93561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------DATAFRAME EXECUTION PLAN----------\n",
            "Query List:\n",
            "1.\n",
            "SELECT  *  FROM (( SELECT \"YEAR\" AS \"YEAR\", \"MONTH\" AS \"MONTH\", \"SEARCH_ENGINE\" AS \"SEARCH_ENGINE\", \"SOCIAL_MEDIA\" AS \"SOCIAL_MEDIA\", \"VIDEO\" AS \"VIDEO\", \"EMAIL\" AS \"EMAIL\" FROM ( SELECT \"YEAR\", \"MONTH\", \"'search_engine'\" AS \"SEARCH_ENGINE\", \"'social_media'\" AS \"SOCIAL_MEDIA\", \"'video'\" AS \"VIDEO\", \"'email'\" AS \"EMAIL\" FROM ( SELECT  *  FROM ( SELECT  *  FROM ( SELECT \"YEAR(DATE)\" AS \"YEAR\", \"MONTH(DATE)\" AS \"MONTH\", \"CHANNEL\", \"TOTAL_COST\" FROM ( SELECT year(\"DATE\") AS \"YEAR(DATE)\", month(\"DATE\") AS \"MONTH(DATE)\", \"CHANNEL\", sum(\"TOTAL_COST\") AS \"TOTAL_COST\" FROM ( SELECT  *  FROM campaign_spend) GROUP BY year(\"DATE\"), month(\"DATE\"), \"CHANNEL\")) ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST) PIVOT (sum(\"TOTAL_COST\") FOR \"CHANNEL\" IN ('search_engine', 'social_media', 'video', 'email'))) ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST)) AS SNOWPARK_LEFT INNER JOIN ( SELECT \"YEAR\" AS \"YEAR\", \"MONTH\" AS \"MONTH\", \"REVENUE\" AS \"REVENUE\" FROM ( SELECT \"YEAR\", \"MONTH\", \"SUM(REVENUE)\" AS \"REVENUE\" FROM ( SELECT \"YEAR\", \"MONTH\", sum(\"REVENUE\") AS \"SUM(REVENUE)\" FROM ( SELECT  *  FROM monthly_revenue) GROUP BY \"YEAR\", \"MONTH\") ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST)) AS SNOWPARK_RIGHT USING (YEAR, MONTH))\n",
            "Logical Execution Plan:\n",
            "GlobalStats:\n",
            "    partitionsTotal=2\n",
            "    partitionsAssigned=2\n",
            "    bytesAssigned=1731072\n",
            "Operations:\n",
            "1:0     ->Result  EXTRACT(year from CAMPAIGN_SPEND.DATE), EXTRACT(month from CAMPAIGN_SPEND.DATE), 'search_engine', 'social_media', 'video', 'email', SUM(MONTHLY_REVENUE.REVENUE)  \n",
            "1:1          ->InnerJoin  joinKey: (EXTRACT(month from CAMPAIGN_SPEND.DATE) = MONTHLY_REVENUE.MONTH) AND (EXTRACT(year from CAMPAIGN_SPEND.DATE) = MONTHLY_REVENUE.YEAR)  \n",
            "1:2               ->Sort  EXTRACT(year from CAMPAIGN_SPEND.DATE) ASC NULLS FIRST, EXTRACT(month from CAMPAIGN_SPEND.DATE) ASC NULLS FIRST  \n",
            "1:3                    ->Pivot  'search_engine', 'social_media', 'video', 'email'  \n",
            "1:4                         ->Sort  EXTRACT(year from CAMPAIGN_SPEND.DATE) ASC NULLS FIRST, EXTRACT(month from CAMPAIGN_SPEND.DATE) ASC NULLS FIRST  \n",
            "1:5                              ->Aggregate  aggExprs: [SUM(CAMPAIGN_SPEND.TOTAL_COST)], groupKeys: [EXTRACT(year from CAMPAIGN_SPEND.DATE), EXTRACT(month from CAMPAIGN_SPEND.DATE), CAMPAIGN_SPEND.CHANNEL]  \n",
            "1:6                                   ->TableScan  A2_DB.A2_SCHEMA.CAMPAIGN_SPEND  CHANNEL, DATE, TOTAL_COST  {partitionsTotal=1, partitionsAssigned=1, bytesAssigned=1728512}\n",
            "1:7               ->Sort  MONTHLY_REVENUE.YEAR ASC NULLS FIRST, MONTHLY_REVENUE.MONTH ASC NULLS FIRST  \n",
            "1:8                    ->Aggregate  aggExprs: [SUM(MONTHLY_REVENUE.REVENUE)], groupKeys: [MONTHLY_REVENUE.YEAR, MONTHLY_REVENUE.MONTH]  \n",
            "1:9                         ->JoinFilter  joinKey: (EXTRACT(month from CAMPAIGN_SPEND.DATE) = MONTHLY_REVENUE.MONTH) AND (EXTRACT(year from CAMPAIGN_SPEND.DATE) = MONTHLY_REVENUE.YEAR)  \n",
            "1:10                              ->TableScan  A2_DB.A2_SCHEMA.MONTHLY_REVENUE  YEAR, MONTH, REVENUE  {partitionsTotal=1, partitionsAssigned=1, bytesAssigned=2560}\n",
            "\n",
            "--------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "snow_df_spend_and_revenue_per_month.explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28334767",
      "metadata": {
        "id": "28334767"
      },
      "source": [
        "### Save Transformed Data into Snowflake Table\n",
        "\n",
        "Let's save the transformed data into a Snowflake table *SPEND_AND_REVENUE_PER_MONTH*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e8ccdd",
      "metadata": {
        "id": "32e8ccdd"
      },
      "outputs": [],
      "source": [
        "snow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fbebea1",
      "metadata": {
        "id": "3fbebea1"
      },
      "source": [
        "### Automation: Run Monthly Revenue Data Transformations As a Snowflake Task\n",
        "\n",
        "*Note: Optionally you can run all these transformations as an automated task by deploying the code to Snowflake as a Snowpark Stored Procedure and executing it as a Snowflake Task. In this task, notice the AFTER campaign_spend_data_pipeline_task clause which makes it a dependant task.*\n",
        "\n",
        "TIP: Learn more about [Stored Procedures](https://docs.snowflake.com/en/sql-reference/stored-procedures-python) and [Snowflake Tasks](https://docs.snowflake.com/en/sql-reference/sql/create-task)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d8c534",
      "metadata": {
        "id": "43d8c534"
      },
      "outputs": [],
      "source": [
        "def monthly_revenue_data_pipeline(session: Session) -> str:\n",
        "  # Load revenue table and transform the data into revenue per year/month using group_by and agg() functions\n",
        "  snow_df_spend_per_month_t = session.table('spend_per_month')\n",
        "  snow_df_revenue_t = session.table('monthly_revenue')\n",
        "  snow_df_revenue_per_month_t = snow_df_revenue_t.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n",
        "\n",
        "  # Join revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training\n",
        "  snow_df_spend_and_revenue_per_month_t = snow_df_spend_per_month_t.join(snow_df_revenue_per_month_t, [\"YEAR\",\"MONTH\"])\n",
        "\n",
        "  # SAVE in a new table for the next task\n",
        "  snow_df_spend_and_revenue_per_month_t.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')\n",
        "\n",
        "# Register data pipelining function as a Stored Procedure so it can be run as a task\n",
        "session.sproc.register(\n",
        "  func=monthly_revenue_data_pipeline,\n",
        "  name=\"monthly_revenue_data_pipeline\",\n",
        "  packages=['snowflake-snowpark-python'],\n",
        "  is_permanent=True,\n",
        "  stage_location=\"@A2_sprocs\",\n",
        "  replace=True)\n",
        "\n",
        "monthly_revenue_data_pipeline_task = \"\"\"\n",
        "  CREATE OR REPLACE TASK monthly_revenue_data_pipeline_task\n",
        "      WAREHOUSE = 'A2_WH'\n",
        "      AFTER campaign_spend_data_pipeline_task\n",
        "  AS\n",
        "      CALL monthly_revenue_data_pipeline()\n",
        "  \"\"\"\n",
        "session.sql(monthly_revenue_data_pipeline_task).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c13679",
      "metadata": {
        "id": "c5c13679"
      },
      "source": [
        "### Resume Tasks\n",
        "\n",
        "*Note: Snowflake Tasks are suspended by default so you need to resume them by executing the following commands.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c75211",
      "metadata": {
        "id": "15c75211"
      },
      "outputs": [],
      "source": [
        "# session.sql(\"alter task monthly_revenue_data_pipeline_task resume\").collect()\n",
        "# session.sql(\"alter task campaign_spend_data_pipeline_task resume\").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db8f244",
      "metadata": {
        "id": "0db8f244"
      },
      "source": [
        "### Suspend Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda7603e",
      "metadata": {
        "id": "eda7603e"
      },
      "source": [
        "*Note: For the sake of this lab, if you resume the above tasks, suspend them to avoid unecessary resource utilization by executing the following commands.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d53e5e",
      "metadata": {
        "id": "59d53e5e"
      },
      "outputs": [],
      "source": [
        "# session.sql(\"alter task campaign_spend_data_pipeline_task suspend\").collect()\n",
        "# session.sql(\"alter task monthly_revenue_data_pipeline_task suspend\").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951e3902",
      "metadata": {
        "id": "951e3902"
      },
      "source": [
        "_For comments and feedback, please reach out to dash.desai@snowflake.com | Follow on [Twitter](https://twitter.com/iamontheinet)_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('snowpark')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 41.012855,
      "end_time": "2021-05-15T09:34:14.646782",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-05-15T09:33:33.633927",
      "version": "2.3.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "4fb0a37530c0004d75c43dbcefc0b8b6ea2fdc6f87c96f7fd6f8cf43b3f551c7"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}